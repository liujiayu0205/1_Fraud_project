PS D:\demo> python fraud2.py
读取训练集...
## 训练集形状：(1296675, 23)
读取测试集...
## 测试集形状：(555719, 23)
删除的列：['Unnamed: 0', 'trans_num', 'cc_num', 'first', 'last', 'street', 'zip', 'dob', 'trans_date_trans_time']

## 训练集缺失值统计：
Series([], dtype: int64)
训练集无缺失值

## 测试集缺失值统计：
Series([], dtype: int64)
测试集无缺失值

D:\demo\fraud2.py:100: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].mode()[0], inplace=True)
D:\demo\fraud2.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].median(), inplace=True)
D:\demo\fraud2.py:100: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].mode()[0], inplace=True)
D:\demo\fraud2.py:100: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].mode()[0], inplace=True)
D:\demo\fraud2.py:100: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].mode()[0], inplace=True)
D:\demo\fraud2.py:100: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].mode()[0], inplace=True)
D:\demo\fraud2.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].median(), inplace=True)
D:\demo\fraud2.py:100: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].mode()[0], inplace=True)
D:\demo\fraud2.py:100: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].mode()[0], inplace=True)
D:\demo\fraud2.py:100: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].mode()[0], inplace=True)
D:\demo\fraud2.py:100: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].mode()[0], inplace=True)
D:\demo\fraud2.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.     

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[col].fillna(df[col].median(), inplace=True)

训练集目标变量分布：
is_fraud
0    1289169
1       7506
Name: count, dtype: int64

测试集目标变量分布：
is_fraud
0    553574
1      2145
Name: count, dtype: int64
时间划分：训练集 1037340 行，验证集 259335 行
Checking whether there is an H2O instance running at http://localhost:54321..... not found.
Attempting to start a local H2O server...
; Java HotSpot(TM) 64-Bit Server VM (build 25.441-b07, mixed mode)
  Starting server from C:\Users\lenovo\anac\Lib\site-packages\h2o\backend\bin\h2o.jar
  Ice root: C:\Users\lenovo\AppData\Local\Temp\tmpt20wneri
  JVM stdout: C:\Users\lenovo\AppData\Local\Temp\tmpt20wneri\h2o_lenovo_started_from_python.out
  JVM stderr: C:\Users\lenovo\AppData\Local\Temp\tmpt20wneri\h2o_lenovo_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  -----------------------------
H2O_cluster_uptime:         04 secs
H2O_cluster_timezone:       Asia/Shanghai
H2O_data_parsing_timezone:  UTC
H2O_cluster_version:        3.46.0.9
H2O_cluster_version_age:    3 months and 1 day
H2O_cluster_name:           H2O_from_python_lenovo_mhb8u2
H2O_cluster_total_nodes:    1
H2O_cluster_free_memory:    7.103 Gb
H2O_cluster_total_cores:    0
H2O_cluster_allowed_cores:  0
H2O_cluster_status:         locked, healthy
H2O_connection_url:         http://127.0.0.1:54321
H2O_connection_proxy:       {"http": null, "https": null}
H2O_internal_security:      False
Python_version:             3.13.5 final
--------------------------  -----------------------------
Parse progress: |████████████████████████████████████████████████████████████████ (done)| 100%
Parse progress: |████████████████████████████████████████████████████████████████ (done)| 100%
Parse progress: |████████████████████████████████████████████████████████████████ (done)| 100%
用于建模的特征数量：17
特征列表：['merchant', 'category', 'amt', 'gender', 'city', 'state', 'lat', 'long', 'city_pop', 'job', 'merch_lat', 'merch_long', 'hour', 'day_of_week', 'day_of_month', 'month', 'is_weekend']

开始 H2O AutoML 训练（时间序列验证）...
AutoML progress: |                                                               |   0%
21:37:04.44: AutoML: XGBoost is not available; skipping it.

AutoML progress: |███████████████████████████████████████████████████████████████ (done)| 100%

AutoML 排行榜（按 AUC 排序）：
model_id                                                   auc    logloss     aucpr    mean_per_class_error       rmse         mse
DeepLearning_1_AutoML_1_20260225_213704               0.964383  0.0236721  0.355996                0.182776  0.0716602  0.00513518
DeepLearning_grid_1_AutoML_1_20260225_213704_model_2  0.963525  0.0749405  0.343367                0.172297  0.0775009  0.00600639
GBM_grid_1_AutoML_1_20260225_213704_model_3           0.960243  0.0421519  0.416946                0.225358  0.0768203  0.00590136
GBM_3_AutoML_1_20260225_213704                        0.949981  0.0502227  0.280078                0.26252   0.0735733  0.00541304
GBM_grid_1_AutoML_1_20260225_213704_model_5           0.946689  0.0544728  0.341337                0.241861  0.0738939  0.0054603
GBM_5_AutoML_1_20260225_213704                        0.94025   0.0482126  0.260857                0.301712  0.0737324  0.00543647
GBM_grid_1_AutoML_1_20260225_213704_model_1           0.92433   0.0498562  0.243781                0.352208  0.0735462  0.00540905
DeepLearning_grid_1_AutoML_1_20260225_213704_model_1  0.90817   0.0351748  0.234107                0.271484  0.0751731  0.005651
DeepLearning_grid_2_AutoML_1_20260225_213704_model_1  0.905076  0.0313697  0.366255                0.286702  0.0688383  0.00473871
GBM_grid_1_AutoML_1_20260225_213704_model_8           0.898264  0.0580609  0.188081                0.430804  0.0736232  0.00542038
GBM_grid_1_AutoML_1_20260225_213704_model_6           0.897923  0.0406714  0.172588                0.281823  0.0760174  0.00577864
GBM_4_AutoML_1_20260225_213704                        0.88825   0.044008   0.161247                0.315381  0.0759087  0.00576214
DRF_1_AutoML_1_20260225_213704                        0.882183  0.0733678  0.366669                0.276978  0.0766126  0.00586949
XRT_1_AutoML_1_20260225_213704                        0.881301  0.0565723  0.630849                0.19023   0.0769294  0.00591814
DeepLearning_grid_1_AutoML_1_20260225_213704_model_5  0.879855  0.0519594  0.170113                0.30159   0.0903767  0.00816794
GBM_grid_1_AutoML_1_20260225_213704_model_7           0.878032  0.044104   0.115933                0.44446   0.0768547  0.00590665
DeepLearning_grid_3_AutoML_1_20260225_213704_model_1  0.87479   0.0380962  0.397094                0.312489  0.0679568  0.00461812
GBM_grid_1_AutoML_1_20260225_213704_model_2           0.872058  0.066174   0.165422                0.429439  0.0738072  0.0054475
GLM_1_AutoML_1_20260225_213704                        0.826395  0.033301   0.193256                0.287124  0.0772322  0.00596481
GBM_1_AutoML_1_20260225_213704                        0.808547  0.0466967  0.227533                0.287155  0.0757656  0.00574043
GBM_2_AutoML_1_20260225_213704                        0.746983  0.0431293  0.109167                0.444425  0.0761804  0.00580346
[21 rows x 7 columns]


最佳模型：
Model Details
=============
H2ODeepLearningEstimator : Deep Learning
Model Key: DeepLearning_1_AutoML_1_20260225_213704


Status of Neuron Layers: predicting is_fraud, 2-class classification, bernoulli distribution, CrossEntropy loss, 21,722 weights/biases, 309.7 KB, 17,397,676 training samples, mini-batch size 1
    layer    units    type       dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias              bias_rms
--  -------  -------  ---------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ---------------------  -------------------
    1        2147     Input      0.0
    2        10       Rectifier  0.0        0.0   0.0   0.009229437757389481   0.08032673597335815    0.0         7.477291508416603e-05  0.04088495671749115  0.2347507490271096     0.37853801250457764
    3        10       Rectifier  0.0        0.0   0.0   0.0054223675956018265  0.0077467747032642365  0.0         -0.02896622150205076   0.46042120456695557  0.8883006756355656     0.14584201574325562
    4        10       Rectifier  0.0        0.0   0.0   0.043954679756134284   0.19609779119491577    0.0         -0.05220742818899453   0.38016653060913086  1.010226899443385      0.06460332870483398
    5        2        Softmax               0.0   0.0   0.015225822772481478   0.038794055581092834   0.0         -0.39137480705976485   1.5256648063659668   0.0027219214726162955  0.1312859058380127

ModelMetricsBinomial: deeplearning
** Reported on train data. **

MSE: 0.13274229832274453
RMSE: 0.3643381647902736
LogLoss: 0.5943630709440364
Mean Per-Class Error: 0.05398060490888919
AUC: 0.9846694363653898
AUCPR: 0.9840157235109389
Gini: 0.9693388727307797

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.005187288807701859
       0     1     Error    Rate
-----  ----  ----  -------  ---------------
0      4755  232   0.0465   (232.0/4987.0)
1      308   4705  0.0614   (308.0/5013.0)
Total  5063  4937  0.054    (540.0/10000.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.00518729   0.945729  392
max f2                       0.00101003   0.960278  397
max f0point5                 0.0276071    0.960047  376
max accuracy                 0.00684723   0.9463    390
max precision                0.884103     0.997559  67
max recall                   1.49739e-05  1         399
max specificity              0.997507     0.999799  0
max absolute_mcc             0.00684723   0.89306   390
max min_per_class_accuracy   0.00405442   0.944145  393
max mean_per_class_accuracy  0.00684723   0.946341  390
max tns                      0.997507     4986      0
max fns                      0.997507     5011      0
max fps                      1.49739e-05  4987      399
max tps                      1.49739e-05  5013      399
max tnr                      0.997507     0.999799  0
max fnr                      0.997507     0.999601  0
max fpr                      1.49739e-05  1         399
max tpr                      1.49739e-05  1         399

Gains/Lift Table: Avg response rate: 50.13 %, avg score: 30.73 %
group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------
1        0.01                        0.975376           1.95492    1.95492            0.98             0.984382     0.98                        0.984382            0.0195492       0.0195492                  95.4917   95.4917            0.0191481
2        0.02                        0.962336           1.99481    1.97487            1                0.968561     0.99                        0.976471            0.0199481       0.0394973                  99.4813   97.4865            0.0390963
3        0.03                        0.952855           1.99481    1.98151            1                0.957417     0.993333                    0.97012             0.0199481       0.0594454                  99.4813   98.1515            0.0590444
4        0.04                        0.944987           1.99481    1.98484            1                0.948121     0.995                       0.96462             0.0199481       0.0793936                  99.4813   98.4839            0.0789925
5        0.05                        0.93711            1.99481    1.98683            1                0.940747     0.996                       0.959845            0.0199481       0.0993417                  99.4813   98.6834            0.0989407
6        0.1                         0.902235           1.99082    1.98883            0.998            0.919906     0.997                       0.939876            0.0995412       0.198883                   99.0824   98.8829            0.198281
7        0.15                        0.859383           1.99082    1.98949            0.998            0.881912     0.997333                    0.920555            0.0995412       0.298424                   99.0824   98.9494            0.297622
8        0.2                         0.793809           1.97088    1.98484            0.988            0.82815      0.995                       0.897454            0.0985438       0.396968                   97.0876   98.4839            0.394963
9        0.3                         0.64213            1.98085    1.98351            0.993            0.720351     0.994333                    0.838419            0.198085        0.595053                   98.085    98.351             0.591644
10       0.4001                      0.232017           1.96691    1.97936            0.986014         0.50261      0.992252                    0.754404            0.196888        0.791941                   96.6914   97.9358            0.785725
11       0.5                         0.00364982         1.51758    1.88709            0.760761         0.0537936    0.946                       0.614422            0.151606        0.943547                   51.7576   88.7094            0.889406
12       0.6                         0.000115754        0.478755   1.65237            0.24             0.000947     0.828333                    0.512176            0.0478755       0.991422                   -52.1245  65.2371            0.784885
13       0.7                         5.78113e-06        0.0698185  1.42629            0.035            3.66962e-05  0.715                       0.439013            0.00698185      0.998404                   -93.0182  42.6292            0.598364
14       0.8                         1.1065e-07         0.0159585  1.25               0.008            1.71099e-06  0.626625                    0.384137            0.00159585      1                          -98.4041  25                 0.401043
15       0.9                         1.82588e-10        0          1.11111            0                1.61021e-08  0.557                       0.341455            0               1                          -100      11.1111            0.200521
16       1                           9.35449e-14        0          1                  0                3.44e-11     0.5013                      0.30731             0               1                          -100      0                  0

ModelMetricsBinomial: deeplearning
** Reported on validation data. **

MSE: 0.005135183587146914
RMSE: 0.07166019527706378
LogLoss: 0.023672052006795907
Mean Per-Class Error: 0.18277593649821536
AUC: 0.9643834601405841
AUCPR: 0.3559955243132808
Gini: 0.9287669202811681

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4728070809386743
       0       1     Error    Rate
-----  ------  ----  -------  -----------------
0      256587  1210  0.0047   (1210.0/257797.0)
1      555     983   0.3609   (555.0/1538.0)
Total  257142  2193  0.0068   (1765.0/259335.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.472807     0.526936  173
max f2                       0.234036     0.612358  242
max f0point5                 0.646151     0.490048  119
max accuracy                 0.833353     0.994108  58
max precision                0.833353     0.505924  58
max recall                   2.48724e-06  1         399
max specificity              0.999818     0.999822  0
max absolute_mcc             0.458671     0.532915  177
max min_per_class_accuracy   0.00122547   0.901143  389
max mean_per_class_accuracy  0.00487822   0.905735  376
max tns                      0.999818     257751    0
max fns                      0.999818     1538      0
max fps                      2.48724e-06  257797    399
max tps                      2.48724e-06  1538      399
max tnr                      0.999818     0.999822  0
max fnr                      0.999818     1         0
max fpr                      2.48724e-06  1         399
max tpr                      2.48724e-06  1         399

Gains/Lift Table: Avg response rate:  0.59 %, avg score:  0.89 %
group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------
1        0.0100025                   0.329189           69.0984     69.0984            0.409792         0.70339      0.409792                    0.70339             0.691157        0.691157                   6809.84   6809.84            0.685219
2        0.0200012                   0.0427297          10.2094     39.6596            0.0605476        0.120186     0.235203                    0.411844            0.102081        0.793238                   920.944   3865.96            0.77785
3        0.0300037                   0.0169843          2.92514     27.4132            0.0173477        0.0268224    0.162576                    0.283487            0.0292588       0.822497                   192.514   2641.32            0.797221
4        0.0400023                   0.00918482         1.75576     21.0001            0.0104126        0.0125101    0.124542                    0.215756            0.0175553       0.840052                   75.5764   2000.01            0.804823
5        0.050001                    0.00576859         1.30057     17.0608            0.00771307       0.00727373   0.10118                     0.174066            0.0130039       0.853056                   30.0566   1606.08            0.807846
6        0.100002                    0.00123361         1.00128     9.03104            0.00593815       0.00273459   0.053559                    0.0884002           0.050065        0.903121                   0.128109  803.104            0.80791
7        0.150003                    0.00044108         0.42912     6.16373            0.00254492       0.000752403  0.0365543                   0.0591843           0.0214564       0.924577                   -57.088   516.373            0.779196
8        0.2                         0.000187874        0.377135    4.71717            0.00223662       0.00029465   0.0279754                   0.0444627           0.0188557       0.943433                   -62.2865  371.717            0.747868
9        0.300002                    4.17141e-05        0.318589    3.25095            0.00188941       9.62913e-05  0.01928                     0.0296737           0.0318596       0.975293                   -68.1411  225.095            0.679319
10       0.4                         9.21967e-06        0.162552    2.47887            0.000964023      2.15884e-05  0.0147011                   0.0222608           0.0162549       0.991547                   -83.7448  147.887            0.595077
11       0.500002                    1.50493e-06        0.0585164   1.99479            0.000347035      4.40666e-06  0.0118302                   0.0178095           0.00585176      0.997399                   -94.1484  99.4791            0.500365
12       0.6                         1.10988e-07        0.0195062   1.66558            0.000115683      5.82058e-07  0.00987783                  0.0148414           0.00195059      0.99935                    -98.0494  66.5583            0.401732
13       0.699998                    3.76688e-09        0.00650208  1.42858            3.85609e-05      3.21496e-08  0.00847224                  0.0127212           0.000650195     1                          -99.3498  42.8575            0.301792
14       0.8                         2.15933e-10        0           1.25               0                1.19072e-09  0.00741319                  0.011131            0               1                          -100      25                 0.201193
15       0.899998                    1.8452e-11         0           1.11111            0                7.9984e-11   0.00658952                  0.00989428          0               1                          -100      11.1113            0.100599
16       1                           5.52721e-14        0           1                  0                6.40009e-12  0.00593055                  0.00890484          0               1                          -100      0                  0

Scoring History:
    timestamp            duration    training_speed    epochs     iterations    samples      training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error
--  -------------------  ----------  ----------------  ---------  ------------  -----------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------
    2026-02-25 21:40:05  0.000 sec                     0          0             0            nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan
    2026-02-25 21:40:06  2.046 sec   227248 obs/sec    0.0483633  1             99762        0.364338         0.594363            0.469027       0.984669        0.984016           1.95492          0.054                            0.0716602          0.0236721             0.128948         0.964383          0.355996             69.0984            0.00680587
    2026-02-25 21:40:16  12.031 sec  370959 obs/sec    1.69747    35            3.50149e+06  0.30366          0.347992            0.631159       0.995668        0.996797           1.99481          0.0082                           0.0571887          0.0371356             0.445236         0.895968          0.632339             73.1286            0.00383288
    2026-02-25 21:40:26  22.102 sec  377913 obs/sec    3.39483    70            7.00273e+06  0.279294         0.284775            0.687977       0.997886        0.99836            1.99481          0.0083                           0.0604677          0.0346635             0.379795         0.901142          0.589452             66.6283            0.00401411
    2026-02-25 21:40:36  32.069 sec  381215 obs/sec    5.08999    105           1.04994e+07  0.209398         0.144562            0.82461        0.999358        0.999037           1.99481          0.0034                           0.0650965          0.0457243             0.281207         0.882073          0.538815             65.1982            0.00445755
    2026-02-25 21:40:45  41.907 sec  382214 obs/sec    6.73872    139           1.39004e+07  0.160554         0.0779968           0.896889       0.999294        0.998746           1.99481          0.003                            0.0663658          0.0547254             0.252903         0.86901           0.514809             63.4431            0.00432259
    2026-02-25 21:40:56  52.255 sec  380759 obs/sec    8.43416    174           1.73977e+07  0.147563         0.0716242           0.9129         0.999077        0.998494           1.99481          0.0043                           0.0762994          0.0674519             0.0125147        0.885432          0.499748             67.9284            0.00485087
    2026-02-25 21:40:57  53.174 sec  380676 obs/sec    8.43416    174           1.73977e+07  0.364338         0.594363            0.469027       0.984669        0.984016           1.95492          0.054                            0.0716602          0.0236721             0.128948         0.964383          0.355996             69.0984            0.00680587

Variable Importances:
variable                                    relative_importance    scaled_importance     percentage
------------------------------------------  ---------------------  --------------------  ----------------------
amt                                         1.0                    1.0                   0.005203622472223954
category.travel                             0.7608334422111511     0.7608334422111511    0.003959089997509452
category.grocery_pos                        0.6910294890403748     0.6910294890403748    0.0035958565781399306
category.misc_pos                           0.5650826692581177     0.5650826692581177    0.0029404768764158375
category.gas_transport                      0.44607484340667725    0.44607484340667725   0.002321205079444767
hour                                        0.44319891929626465    0.44319891929626465   0.0023062398561154132
category.misc_net                           0.39755284786224365    0.39755284786224365   0.002068714933032602
category.health_fitness                     0.38981252908706665    0.38981252908706665   0.0020284372363119137
category.kids_pets                          0.3855091631412506     0.3855091631412506    0.0020060441445700623
category.shopping_pos                       0.3791360557079315     0.3791360557079315    0.0019728808995121455
---                                         ---                    ---                   ---
job.Museum/gallery conservator              0.031496159732341766   0.031496159732341766  0.00016389412457196883
job.Chemist, analytical                     0.031484123319387436   0.031484123319387436  0.0001638314916230347
merchant.fraud_Hills, Hegmann and Schaefer  0.029900234192609787   0.029900234192609787  0.00015558953056942333
merchant.fraud_Hackett-Lueilwitz            0.02757495455443859    0.02757495455443859   0.00014348965319003093
city.missing(NA)                            0.0                    0.0                   0.0
merchant.missing(NA)                        0.0                    0.0                   0.0
job.missing(NA)                             0.0                    0.0                   0.0
state.missing(NA)                           0.0                    0.0                   0.0
category.missing(NA)                        0.0                    0.0                   0.0
gender.missing(NA)                          0.0                    0.0                   0.0
[2147 rows x 4 columns]


测试集评估结果：
ModelMetricsBinomial: deeplearning
** Reported on test data. **

MSE: 0.004163140390082287
RMSE: 0.06452240223428052
LogLoss: 0.020297255886995626
Mean Per-Class Error: 0.2078218155416367
AUC: 0.9515182788880121
AUCPR: 0.2583305383563383
Gini: 0.9030365577760242

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4559984205492269
       0       1     Error    Rate
-----  ------  ----  -------  -----------------
0      551367  2208  0.004    (2208.0/553575.0)
1      883     1262  0.4117   (883.0/2145.0)
Total  552250  3470  0.0056   (3091.0/555720.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.455998     0.44951   184
max f2                       0.243389     0.552888  246
max f0point5                 0.562258     0.396672  152
max accuracy                 0.999637     0.995894  0
max precision                0.625501     0.377539  132
max recall                   2.471e-06    1         399
max specificity              0.999637     0.999753  0
max absolute_mcc             0.277232     0.466192  236
max min_per_class_accuracy   0.000399925  0.885315  394
max mean_per_class_accuracy  0.00107366   0.895956  389
max tns                      0.999637     553438    0
max fns                      0.999637     2145      0
max fps                      2.471e-06    553575    399
max tps                      2.471e-06    2145      399
max tnr                      0.999637     0.999753  0
max fnr                      0.999637     1         0
max fpr                      2.471e-06    1         399
max tpr                      2.471e-06    1         399

Gains/Lift Table: Avg response rate:  0.39 %, avg score:  0.61 %
group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------
1        0.0100014                   0.0851716          70.9921     70.9921            0.274019         0.561137     0.274019                    0.561137            0.710023        0.710023                   6999.21   6999.21            0.702734
2        0.0200011                   0.0119256          6.29393     38.6459            0.0242937        0.0304627    0.149168                    0.295824            0.0629371       0.77296                    529.393   3764.59            0.755877
3        0.0300007                   0.0050367          2.98379     26.7593            0.011517         0.00775026   0.103287                    0.199805            0.0298368       0.802797                   198.379   2575.93            0.775791
4        0.0400004                   0.00280079         1.39865     20.4194            0.0053986        0.00374503   0.078816                    0.150792            0.013986        0.816783                   39.8652   1941.94            0.779793
5        0.05                        0.00175983         2.05136     16.7459            0.00791794       0.00221755   0.0646369                   0.121078            0.0205128       0.837296                   105.136   1574.59            0.790347
6        0.1                         0.000397997        0.885781    8.81585            0.00341899       0.000860336  0.0340279                   0.0609694           0.044289        0.881585                   -11.4219  781.585            0.784614
7        0.15                        0.000144024        0.634033    6.08858            0.00244728       0.000244356  0.023501                    0.0407277           0.0317016       0.913287                   -36.5967  508.858            0.766244
8        0.2                         6.2072e-05         0.484848    4.68765            0.00187145       9.6412e-05   0.0180936                   0.0305699           0.0242424       0.937529                   -51.5152  368.765            0.740387
9        0.3                         1.39867e-05        0.25641     3.21057            0.000989707      3.18891e-05  0.0123923                   0.0203906           0.025641        0.96317                    -74.359   221.057            0.66574
10       0.4                         3.16135e-06        0.242424    2.46853            0.000935723      7.33761e-06  0.00952818                  0.0152947           0.0242424       0.987413                   -75.7576  146.853            0.589689
11       0.5                         5.43149e-07        0.0745921   1.98974            0.000287915      1.53918e-06  0.00768013                  0.0122361           0.00745921      0.994872                   -92.5408  98.9744            0.496789
12       0.6                         4.13156e-08        0.037296    1.66434            0.000143957      2.13323e-07  0.0064241                   0.0101968           0.0037296       0.998601                   -96.2704  66.4336            0.400146
13       0.7                         1.26722e-09        0.00932401  1.42791            3.59893e-05      1.15991e-08  0.00551151                  0.00874011          0.000932401     0.999534                   -99.0676  42.7905            0.300694
14       0.8                         7.35034e-11        0.004662    1.25               1.79947e-05      3.94041e-10  0.00482482                  0.00764759          0.0004662       1                          -99.5338  25                 0.200775
15       0.9                         7.60385e-12        0           1.11111            0                2.82797e-11  0.00428873                  0.00679786          0               1                          -100      11.1111            0.100387
16       1                           2.95983e-14        0           1                  0                2.89257e-12  0.00385986                  0.00611808          0               1                          -100      0                  0

## 最佳模型已保存至：D:\demo\models\DeepLearning_1_AutoML_1_20260225_213704
H2O session _sid_b8c5 closed.

您第二次运行的结果显示模型性能有了**显著提升**，测试集 AUC 从第一次的 **0.689** 提高到了 **0.951**，AUCPR 也从 **0.071** 上升到 **0.258**。这表明我们针对过拟合所做的改进（删除标识特征、时间特征工程、时间序列验证）是有效的。不过，模型在少数类（欺诈）上的精确率-召回率表现（AUCPR）仍有提升空间。以下是对日志的详细解读及进一步优化建议。

---

##  本次运行：

| 指标                | 训练集          | 验证集 (时间后20%) | 测试集          |
|---------------------|-----------------|--------------------|-----------------|
| AUC                 | 0.9847          | 0.9644             | **0.9515**      |
| AUCPR               | 0.9840          | 0.3560             | **0.2583**      |
| 最佳阈值下召回率    |                  | 63.9% (983/1538)   | 58.8% (1262/2145) |
| 最佳阈值下精确率    |                  | 44.8%              | 36.4%            |
| 最佳阈值下 F1       |                 | 0.527              | 0.450            |

- **最佳模型**：`DeepLearning_1_AutoML_1_20260225_213704`（深度学习）
- **特征数量**：17个（包括 `amt`, `category`, `hour` 等）
- **运行时间**：约 10 分钟

---

##  改进效果

1. **过拟合大幅缓解**  
   - 第一次运行：训练集 AUC 0.956，测试集 AUC 0.689，差距大。  
   - 本次运行：训练集 AUC 0.985，验证集 0.964，测试集 0.952，差距缩小，说明时间序列验证和特征清洗有效防止了时间泄露和标识符过拟合。

2. **欺诈检测能力提升**  
   - 测试集召回率从 **14.2%** 提升至 **58.8%**，精确率从 **21.0%** 提升至 **36.4%**。  
   - 虽然仍漏掉约 41% 的欺诈，但已能捕获大部分欺诈，误报率也控制在低水平（2208 笔误报，占正常交易的 0.4%）。

3. **时间特征贡献显著**  
   - 特征重要性中 `hour` 排在第5位，欺诈行为具有明显的时间模式，提取小时、星期等特征有助于模型学习。

4. **深度学习优于集成模型**  
   - 排行榜上前几名均为深度学习模型，而第一次的堆叠模型未出现。这可能是因为深度学习配合早停（验证集监控）能更好地泛化，而复杂的集成模型在训练集上容易过拟合。

---

## 问题

### 1. AUCPR 偏低（0.258）
   - AUCPR（精确率-召回率曲线下面积）是衡量不平衡分类的更敏感指标。0.258 意味着模型对欺诈样本的排序能力尚可，但精确率和召回率的平衡不佳。  
   - 验证集 AUCPR 为 0.356，测试集降至 0.258，表明模型在时间分布变化下，对少数类的预测置信度有所下降。

### 2. 召回率仍有提升空间
   - 在最佳阈值下，测试集召回率 58.8%，即仍有 41.2% 的欺诈未被识别。希望召回率更高。

### 3. 验证集与测试集分布差异
   - 验证集（训练集最后20%时间）与测试集（完全独立的时间段）可能存在分布漂移，导致性能下降。是时间序列问题的常见挑战。

---

## 进一步优化

### 1. **调整类别不平衡处理**
   - 当前使用了 `balance_classes=True` 和 `max_after_balance_size=3.0`，可尝试更激进的过采样（如增大 `max_after_balance_size` 到 5.0）或使用 SMOTE 等高级采样。
   - 或尝试 **代价敏感学习**：在 AutoML 中设置 `weights_column`，对欺诈样本赋予更高权重。

### 2. **优化模型选择指标**
   - 排行榜目前按 AUC 排序，但 AUC 对不平衡数据不够敏感。可以改为按 **AUCPR** 排序：`sort_metric="AUCPR"`，这样 AutoML 将优先选择对少数类预测能力强的模型。
   - 从排行榜看，XRT（极度随机树）的验证集 AUCPR 达到 0.631，远高于深度学习的 0.356，但因其 AUC 较低未被选为最佳。若以 AUCPR 为目标，XRT 可能更适合。

### 3. **进一步特征工程**
   - **目标编码**：对高基数分类变量（如 `merchant`、`job`、`city`）进行目标编码（用历史欺诈率替代），需在交叉验证中避免泄露。  
   - **聚合特征**：按卡号（已删除）或用户维度统计历史交易行为（如平均金额、交易频率），需确保测试集中新卡号能处理。
   - **交互特征**：金额与商户类别的组合，或地理位置与时间组合。

### 4. **阈值优化**
   - 当前报告的最佳阈值（0.456）是根据验证集 F1 最大确定的，可调整阈值以平衡召回率和精确率。  
   - 例如，将阈值降低到 0.2，可能召回率升至 70% 以上，但精确率会下降，需根据业务容忍度选择。

### 5. **集成模型再尝试**
   - 虽然深度学习表现好，但堆叠模型在第一次运行中过拟合严重，可能因为时间泄露。现在有了时间验证，可以重新尝试堆叠，但需严格控制早停和验证集。

### 6. **增加验证集规模或使用滚动验证**
   - 当前验证集为最后 20% 时间（约 26 万行），可尝试更细的时间折（如 5 折时间序列交叉验证），但需手动实现（H2O 不直接支持）。  
   - 或用 **多个时间窗口验证**，例如用前 60% 训练，接下来 20% 验证，最后 20% 测试，更贴近实际。

---

## 总结

第二版代码成功解决了第一版的严重的过拟合问题，使模型在测试集上达到了 **AUC 0.95** 的较好水平，欺诈召回率提升至 **58.8%**。但 AUCPR 仍有较大提升空间，还要注意模型在时间分布变化下性能略有下降。

下一步优化方向：若追求更高的召回率，可调整阈值或采样比例（捕获更多欺诈，减少损失，但增加误报成本，需平衡两者）；若希望整体排序更优，可改用 AUCPR 作为 AutoML 排序指标并尝试其他模型（获得灵活的模型，可根据业务需求调整阈值，便于长期部署和迭代）。

在信用卡欺诈检测业务中，模型的目标是最大化减少欺诈损失，同时最小化对正常交易的干扰。不同的优化目标会直接导致不同的业务结果。以下结合你的日志数据，详细解释追求高召回率与追求整体排序更优在实际业务中的含义和权衡。



## ------追求更高召回率的业务结果------

### 业务目标：**最小化欺诈损失**

- **操作方式**：降低分类阈值，让更多交易被判定为欺诈，从而提高召回率。
- **业务结果**：
  - **捕获更多欺诈**：例如，若召回率从当前的 **58.8%** 提升至 **80%**，则测试集中 **2145** 个欺诈样本中将有 **1716** 个被拦截，比当前多拦截 **454** 个欺诈。
  - **减少欺诈损失**：假设平均欺诈金额为 `amt`，则减少的损失为 `454 × 平均欺诈金额`。假设平均欺诈金额为 100 美元，则减少损失约 45,400 美元。
  - **代价**：将正常交易判为欺诈的情况会显著增加。比如，精确率36.4%，若召回率提升，精确率降至 20% 或更低。这意味着每拦截 1 个欺诈，会误拦约 4 个正常交易，造成客户不满、客服投诉、人工审核成本提高等情况。


## ------追求整体排序更优（高AUC/AUCPR）的业务结果------

### 业务目标：**灵活平衡，适应多种业务需求**

- **操作方式**：以 AUCPR 或 AUC 作为模型优化目标，训练一个区分能力强的模型，然后根据实际成本调整阈值。
- **业务结果**：
  - **获得一个鲁棒的排序器**：高 AUC（0.95）意味着无论阈值如何，模型都能很好地将欺诈排在正常交易前面。为业务团队提供灵活性。
  - **可定制阈值**：可以根据季节、市场活动或成本变化，动态调整阈值，在召回率和精确率之间取得最优平衡。
    - 例如，在促销期间，注重客户体验，采用高精确率阈值（误报少）。
    - 在欺诈高峰期，则采用高召回率阈值（多拦截）。
  - **便于评估模型迭代**：AUC 不受阈值影响，适合比较不同模型的质量。
- **代价**：单一的排序指标不能直接告诉业务具体能拦截多少欺诈，需要结合业务成本分析确定最佳阈值。




第二版所训练出的模型已具备良好的排序能力（AUC 0.95），接下来需结合业务成本选择最优阈值，即可在实际应用中发挥最大价值。