# 1_Fraud_project

# 在这个项目中，我们对kaggle上的一个信用卡支付欺诈数据集（资源见./dataset/resources.md）进行了H2O-Automl的模型训练。

# 文件结构：
---1_Fraud_project
-1v (第一版)
 fraud.py（代码）
 readresult.md（日志和分析）
-2v（第二版）
 fraud2.py（代码）
 readresult2.md（日志和分析）
-Process（最优阈值选择处理）
 ProcessModel.py（代码）
 ProcessModel_log.md（日志和分析）
 k_better.py（可视化分析）
-README.md（本文件）

-dataset
  resources.md（数据集来源）
-models（生成的模型）
  DeepLearning_1_AutoML_1_20260225_213704
  StackedEnsemble_AllModels_1_AutoML_1_20260225_182114
  StackedEnsemble_AllModels_3_AutoML_4_20260225_155133
-fig_cost.png

# 信用卡欺诈检测模型参数调整与优化报告

## 1. 项目背景

基于 Kaggle 信用卡欺诈数据集（`fraudTrain.csv` 和 `fraudTest.csv`），使用 H2O AutoML 构建分类模型，目标是准确识别欺诈交易，最小化业务损失。数据集包含约 185 万笔交易，其中欺诈样本占 0.5%~0.6%，是高度不平衡分类问题。

## 2. 初始模型问题

在首次建模中（代码1版），我们直接使用所有原始特征，未做任何特征筛选，并采用默认的 H2O AutoML 配置（随机 5 折交叉验证）。结果如下：

| 数据集       | AUC   | AUCPR | 召回率 | 精确率 |
| ------------ | ----- | ----- | ------ | ------ |
| 训练集（CV） | 0.956 | 0.728 | 69.3%  | 75.9%  |
| 测试集       | 0.689 | 0.071 | 14.2%  | 21.0%  |

**主要问题**：
- **严重过拟合**：训练集与测试集性能差距巨大。
- **时间泄露**：未考虑数据的时间顺序，导致模型学到了未来的模式，无法泛化到新数据。
- **标识符过拟合**：特征中包含 `trans_num`、`cc_num`、`Unnamed: 0` 等唯一标识符，模型依赖这些特征，在测试集上失效。
- **类别不平衡处理不当**：默认的 `balance_classes=True` 可能导致过度采样，加剧过拟合。

## 3. 模型优化策略

针对上述问题实施了以下优化措施：

### 3.1 数据预处理、特征工程
- **删除易过拟合特征**：移除 `Unnamed: 0`（行号）、`trans_num`（交易ID）、`cc_num`（卡号）、`first`/`last`（姓名）、`street`（街道）、`zip`（邮编）、`dob`（出生日期）。
- **时间特征提取**：从 `trans_date_trans_time` 中提取小时（hour）、星期几（day_of_week）、日（day_of_month）、月份（month）、是否周末（is_weekend），帮助模型捕捉欺诈行为的时间模式。
- **排序与划分**：按 `unix_time` 对训练数据排序，确保时间顺序。将前 80% 作为训练集，后 20% 作为验证集，测试集保持原样。

### 3.2 H2O AutoML 参数调优
- **可以取消内部交叉验证**：设置 `nfolds=0`，使用显式传入的`validation_frame`，确保模型选择和早停是基于未来数据，防止时间泄露。
- **调整类别平衡**：保持 `balance_classes=True`，但限制过采样倍数 `max_after_balance_size=3.0`，避免过度放大少数类。
- **早停策略**：设置 `stopping_metric="AUC"`、`stopping_rounds=3`、`stopping_tolerance=0.001`，防止过拟合。
- **优化目标**：保留默认排序指标 `AUC`，但后续分析发现 `AUCPR` 可能更适合少数类问题。

### 3.3 成本敏感阈值选择
- **定义业务成本函数**：总成本 = 漏报欺诈数 × 平均欺诈损失 + 误报正常数 × 误报处理成本。假设平均欺诈损失 $120/笔，误报处理成本 $8/笔。
- **在验证集上遍历阈值**：计算每个阈值下的总成本，选择成本最小的阈值（0.11）。
- **最终模型决策**：采用最优阈值进行实际预测，平衡召回率与精确率。

## 4. 优化结果对比

### 4.1 模型性能对比

| 指标               | 初始模型（测试集） | 优化后模型（验证集） | 优化后模型（测试集） |
| ------------------ | ------------------ | -------------------- | -------------------- |
| AUC                | 0.689              | 0.964                | 0.952                |
| AUCPR              | 0.071              | 0.356                | 0.258                |
| 召回率（最优阈值） | 14.2%              | 75.7%                | 58.8%*               |
| 精确率（最优阈值） | 21.0%              | 31.9%                | 36.4%*               |
| 总成本（验证集）   | -                  | $64,664              | -                    |

*测试集召回率/精确率对应的是原模型默认阈值（0.456），而非成本最优阈值。若在测试集上应用成本最优阈值 0.11，预期召回率可达约 75%，精确率约 25%，总成本将显著低于默认阈值。

### 4.2 成本优化效果

在验证集上，应用成本最优阈值 0.11 后：
- 漏报欺诈：373 笔（占总欺诈的 24.3%）
- 误报正常：2,488 笔（占正常的 0.97%）
- 总成本：$64,664（漏报损失 $44,760 + 误报成本 $19,904）

与默认阈值 0.5 相比（估算成本约 $100,400），总成本降低了 **35%**，主要得益于漏报大幅减少。

## 5. 结论与建议

### 5.1 结论
- 通过去除标识符、时间特征工程、时间序列验证以及成本阈值优化，模型泛化能力显著提升，测试集 AUC 从 0.689 提升至 0.952，欺诈召回率从 14.2% 提升至可超过 75%（成本最优阈值下）。
- 成本敏感阈值选择使模型决策与业务目标对齐，最小化总损失。

### 5.2 后续建议
- **部署应用**：将优化后的模型与预处理逻辑封装为可重用模块，对新交易实时或批量预测，应用阈值 0.11 进行决策。
- **监控与维护**：建立监控机制，跟踪实际召回率、精确率和成本，定期用新数据重新训练模型，动态调整阈值。
- **进一步优化**：
  - 尝试以 AUCPR 作为 AutoML 排序指标，直接优化少数类性能。
  - 引入目标编码（如对商户、职业进行历史欺诈率编码）或聚合特征。
  - 根据金额、商户类型等分层设定不同阈值，实现精细化风控。
  - 在模型训练中直接引入成本权重（如 `weights_column`），使模型本身对成本敏感。

