# AutoML 自动化机器学习项目方案设计大纲

## 一、项目概述

### 1.1 目标与范围
- **业务目标**：在有限人力下，通过自动化流程完成数据到可部署模型的端到端建模，提升建模效率与可复现性。
- **技术范围**：涵盖数据接入、特征工程、模型选择与调参、评估与阈值优化、模型部署与监控。
- **适用场景**：表格数据分类/回归、时间序列预测、不平衡分类（如欺诈检测）等。

### 1.2 核心原则
- **可复现**：固定随机种子、版本化数据与代码、记录超参与实验。
- **防泄露**：时间序列按时间划分、避免标识符入模、交叉验证与验证集策略明确。
- **业务对齐**：评估指标与业务成本一致，支持阈值/决策优化。

---

## 二、整体架构

### 2.1 系统分层
```
┌─────────────────────────────────────────────────────────────┐
│  应用层：API / 批预测 / 报表 / 监控告警                         │
├─────────────────────────────────────────────────────────────┤
│  模型层：模型注册、版本管理、A/B 测试、回滚                      │
├─────────────────────────────────────────────────────────────┤
│  AutoML 引擎：特征工程 → 模型搜索 → 集成 → 评估 → 阈值优化       │
├─────────────────────────────────────────────────────────────┤
│  数据层：原始数据、特征库、训练/验证/测试划分、元数据             │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 技术选型维度
- **AutoML 框架**：H2O AutoML、Auto-sklearn、FLAML、TPOT、Google Cloud AutoML 等。
- **运行环境**：本地/集群（Spark、Dask）、云（GPU/CPU 资源、调度）。
- **数据与特征**：离线数仓、实时特征、特征存储（Feast 等）。

---

## 三、数据与特征

### 3.1 数据接入与校验
- 数据源定义（表/文件/API）、更新频率、分区与增量策略。
- 质量校验：缺失率、分布漂移、重复与异常值检测。
- 标注与样本权重：正负样本定义、业务权重列（如成本敏感）。

### 3.2 特征工程流水线
- **清洗**：去标识符（ID、姓名、卡号等易过拟合字段）、缺失与异常值处理。
- **构造**：时间特征（小时、星期、是否周末等）、分箱、交叉特征、聚合特征。
- **编码**：类别编码（One-Hot、Target Encoding）、数值标准化/归一化。
- **选择**：方差过滤、相关性/共线性、基于模型的重要性、业务规则保留。

### 3.3 数据划分策略
- **随机划分**：适用于 IID 数据，K 折交叉验证。
- **时间序列划分**：按时间排序，前 80% 训练、中间验证、最后测试，避免未来信息泄露。
- **分层划分**：保持类别比例或关键维度比例。

---

## 四、AutoML 引擎设计

### 4.1 搜索空间
- **算法池**：GLM、GBM、RF、XGBoost、LightGBM、深度学习、集成等。
- **超参数**：学习率、树深度、正则化、早停轮数、采样与类别平衡参数。
- **约束**：最大训练时间、最大模型数、资源上限（内存/GPU）。

### 4.2 搜索与优化策略
- 贝叶斯优化、网格/随机搜索、多目标优化（精度 vs 延迟）。
- 早停：基于验证集指标（如 AUC、AUCPR）与容忍度。
- 针对不平衡：`balance_classes`、`max_after_balance_size`、样本权重列。

### 4.3 验证与模型选择
- **验证方式**：单次验证集 / K 折 CV；时间序列场景优先单次时间划分。
- **排序指标**：AUC、AUCPR（不平衡）、RMSE、自定义损失。
- **集成**：Stacked Ensemble、Blending；可选仅保留单模型以降低复杂度。

### 4.4 阈值与决策优化
- 在验证集上遍历分类阈值，按业务成本函数（漏报成本、误报成本）选最优阈值。
- 可选：按人群/场景分层设定不同阈值。

---

## 五、评估与报告

### 5.1 评估体系
- **泛化**：测试集上的 AUC、AUCPR、召回率、精确率、F1、业务成本。
- **稳定性**：训练/验证/测试一致性，过拟合检测。
- **可解释性**：特征重要性、SHAP、部分依赖（按需）。

### 5.2 实验与报告
- 实验记录：数据版本、特征版本、AutoML 配置、最佳模型 ID、指标与阈值。
- 报告内容：排行榜、最优模型与阈值、成本曲线、混淆矩阵、改进建议。

---

## 六、部署与运维

### 6.1 模型交付
- 模型序列化与存储（二进制、ONNX 等），版本标签与元数据。
- 预处理与后处理流水线一并打包（特征工程、阈值、业务规则）。

### 6.2 服务方式
- **实时**：低延迟 API，特征在线计算或从特征库读取。
- **批量**：定时任务、数据管道触发，写回数仓或下游系统。

### 6.3 监控与迭代
- 监控：请求量、延迟、预测分布、实际标签反馈（若可得）。
- 漂移检测：特征分布、正率、性能指标下滑告警。
- 迭代策略：定期重训、触发式重训（性能/漂移阈值）、A/B 测试新模型。

---

## 七、项目阶段与里程碑

| 阶段       | 内容                           | 产出                     |
|------------|--------------------------------|--------------------------|
| 需求与数据 | 业务目标、指标、数据摸底与划分  | 数据说明文档、划分方案   |
| 特征与流水线 | 特征工程、自动化流水线         | 特征列表、预处理代码/配置 |
| AutoML 闭环 | 配置引擎、跑通训练与评估       | 最佳模型、评估报告、阈值  |
| 部署与监控 | 上线、监控与告警               | 服务、监控大盘、SOP      |
| 持续优化   | 重训策略、新特征、新算法       | 迭代实验记录与模型版本   |

---

## 八、风险与对策

| 风险           | 对策                                       |
|----------------|--------------------------------------------|
| 过拟合         | 去标识符、时间划分、早停、正则化、简化模型  |
| 数据泄露       | 严格时间顺序、避免未来信息、验证集独立使用  |
| 不平衡表现差   | AUCPR 排序、类别平衡/权重、成本敏感阈值     |
| 资源与时效     | 限时/限模型数、分布式、模型压缩与剪枝       |
| 可解释与合规   | 特征约束、可解释模型优先、SHAP/规则补充     |

---

## 九、与本项目（欺诈检测）的对应关系

- **数据与特征**：对应 README 中的“删除易过拟合特征、时间特征、按 unix_time 划分”。
- **AutoML 配置**：对应“nfolds=0 + validation_frame、balance_classes、早停、stopping_metric=AUC”。
- **阈值优化**：对应“成本函数、在验证集上选最优阈值（如 0.11）”。
- **后续可做**：以 AUCPR 为排序指标、`weights_column` 成本加权、分层阈值、目标编码等。

---

*文档版本：v1.0 | 可与现有 1_Fraud_project 实践结合使用*
